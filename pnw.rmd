---
title: ""
runtime: shiny
output: html_document
---

# *Generating Next Word Predictions*

The algorithm generating the next word prediction tables seen on the main page tries to find the most likely n-grams match the user input. The algorithm will always try to use the most context possible, so it starts searching the fivegram tables first (if enough words were typed) before resorting to lower order n-grams. The highest order n-gram used to train the model are fivegrams, so by default if the user has typed in four or more words, the algorithm searches the fivegram table where the first four words match the input's first four words, then orders the matches by probability. If more than five matches are found, the algorithm simply returns the top five matches based the associated probability value in descending order. 

If less than five matches or no matches are found, the algorithm backs off to fourgrams, then trigrams, and so on and so forth until at least one candidate is found. In any case, the function always outputs the top five most common unigrams observed in the testing set as a final resort if no candidates are found or the user mashes randomly on their keyboard. If potential candidates are found from multiple orders of n-grams, the results are combined and reordered by probability.

For efficiency, the algorithm counts the number of times the pattern "space followed by an alphabetic character" appears in the user's input to determine which order n-gram table to begin searching in. For example, if the words "what's going on" are typed, the pattern occurs twice and the algorithm knows to check the fourgram table first for next word predictions and skip checking the fivegram table. If this pattern is seen more than twice, then it is always the case that the user has input at least four words and the fivegram table is always checked. It is also important to mention here that input strings are normalized before any matching is done, and if the user has input more than four words, only the last four words are retrieved.

Model performance was evaluated using a benchmarking tool used by other students in the data science capstone.
Accuracy is among the highest reported and memory usage is among the lowest. 

|    Benchmark            |  Result    |
| :---                     | :---   |
| Overall top-3 score     |  17.80 %    |
| Overall top-1 precision  | 13.56 %    |
| Overall top-3 precision |  21.50 %    |
| Average runtime          | 88.50 msec |
| Number of predictions   |  28464    |
| Total memory used       |  143.14 MB |

